{
    "text": "With the rapid progress of artificial intelligence, an increasing number of industries are relying on the accuracy and efficiency of deep learning algorithms. However, the inherent inexplicability and black box effect of deep neural networks mean that results are often obtained without a clear understanding of the underlying reasoning. This lack of transparency has sparked skepticism and resistance towards deep learning technologies in certain circles. In domains like emotion analysis for business and public opinion monitoring, decision-makers may find it challenging to trust outcomes generated by seemingly emotionless machines without explanations. While mathematical-based explanation methods exist, they tend to treat emotion analysis as a straightforward classification task, neglecting the nuanced human-specific factors and logic involved in emotions. This paper puts forth an emotion analysis explanation framework rooted in psychological theories that delve into stimuli from classic emotion theories. The framework places emphasis on exploring the cause and trigger of emotions as explanations for deep learning-based emotion analysis, comprising two main components: identifying the emotion cause and visualizing emotion-triggering words.",
    "label": 1,
    "type": 3,
    "name": "fid-051"
}