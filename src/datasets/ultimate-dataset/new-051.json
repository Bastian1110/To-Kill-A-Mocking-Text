{
    "text": "As artificial intelligence advances rapidly, many industries are increasingly reliant on the accuracy and efficiency of deep learning algorithms. However, the inherent opacity and black box effect of deep neural networks mean that results are often obtained without a clear understanding of the underlying reasoning. This lack of transparency has led to skepticism and resistance toward deep learning technologies in certain quarters. In contexts such as emotion analysis for business and public opinion monitoring, decision-makers may find it challenging to trust the outcomes generated by seemingly emotionless machines without explanations. While mathematical-based explanation methods exist, they typically treat emotion analysis as a classification task, overlooking the unique human-specific factors and logic involved in emotions. This paper proposes an emotion analysis explanation framework grounded in psychological theories that focus on stimuli from classic emotion theories. The framework prioritizes exploring the cause and trigger of emotions as explanations for deep learning-based emotion analysis, with two main components: identifying the emotion cause and visualizing emotion-triggering words.",
    "label": 0,
    "type": 7,
    "name": "new-051"
}