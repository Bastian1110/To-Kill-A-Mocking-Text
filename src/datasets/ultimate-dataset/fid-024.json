{
    "text": "Recent advancements in technology have empowered computers to discern and classify facial expressions, allowing them to determine an individual's emotional state in images or videos. This process, known as Facial Expression Recognition (FER), has emerged as a highly prominent research field within computer vision. In recent years, deep FER systems have been primarily focused on tackling two significant challenges: overfitting due to limited availability of training data, and the presence of expression-unrelated variations such as illumination, head pose, image resolution, and identity bias. This paper provides an extensive survey on deep FER, covering algorithms and datasets that shed light on these intrinsic challenges. Initially, the paper presents a detailed timeline highlighting the evolution of methods and datasets in deep facial expression recognition. This timeline illustrates the progression and development of techniques and data resources utilized in FER. Subsequently, it introduces a comprehensive review of FER methods, covering the fundamental principles of FER including preprocessing, feature extraction, and classification methods, transitioning from traditional methods employing handcrafted features like SVM and HOG to the deep learning era. Additionally, it offers an overview of benchmark datasets categorized into controlled environments (lab) and uncontrolled environments (in the wild), used for evaluating various FER methods, along with a comparison of different FER models. The paper also discusses existing deep neural networks and associated training strategies tailored for FER, focusing on both static images and dynamic image sequences. Finally, it outlines the remaining challenges, potential opportunities, and future directions for designing robust deep FER systems.",
    "label": 1,
    "type": 4,
    "name": "fid-024"
}