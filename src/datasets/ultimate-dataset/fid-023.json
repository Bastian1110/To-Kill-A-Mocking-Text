{
    "text": "Recent advancements in technology have empowered computers to recognize and categorize facial expressions, determining a person’s emotional state in images or videos. This process, known as “Facial Expression Recognition (FER)”, has emerged as a prominent research field within computer vision. In recent years, deep FER systems have focused primarily on addressing two significant challenges: the issue of overfitting due to limited training data availability, and the presence of expression-unrelated variations, including illumination, head pose, image resolution, and identity bias. This paper provides a comprehensive survey of deep FER, covering algorithms and datasets that shed light on these inherent challenges. Initially, a detailed timeline is presented, showcasing the evolution of methods and datasets in deep facial expression recognition (FER). This timeline illustrates the progression and development of techniques and data resources utilized in FER. Subsequently, a comprehensive review of FER methods is introduced, covering the fundamental principles of FER (such as preprocessing, feature extraction, and classification methods) from the pre-deep learning era (traditional methods employing handcrafted features like SVM and HOG) to the deep learning era. Additionally, a brief overview is provided of the benchmark datasets (classified into controlled environments (lab) and uncontrolled environments (in the wild)) used to evaluate various FER methods, along with a comparison of different FER models. The paper discusses existing deep neural networks and relevant training strategies tailored for FER, focusing on both static images and dynamic image sequences. Finally, it outlines the remaining challenges and potential opportunities in FER, along with future directions for designing robust deep FER systems.",
    "label": 1,
    "type": 3,
    "name": "fid-023"
}