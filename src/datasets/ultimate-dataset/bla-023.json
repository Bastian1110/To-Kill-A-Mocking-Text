{
    "text": "Recent advancements in technology have empowered computers to identify and classify facial expressions, thereby discerning an individual's emotional state in both images and videos. This process, known as 'Facial Expression Recognition (FER)', has emerged as a prominent research area within the realm of computer vision. In recent years, deep FER systems have been primarily focused on addressing two key challenges: the issue of overfitting stemming from limited training data availability, and the presence of expression-unrelated variations such as illumination, head pose, image resolution, and identity bias. This paper offers a comprehensive survey of deep FER, encompassing algorithms and datasets that shed light on these inherent challenges. Initially, the paper presents a detailed timeline elucidating the evolution of methods and datasets in deep facial expression recognition (FER), showcasing the progression and refinement of techniques and data resources utilized in FER. Subsequently, a comprehensive review of FER methods is presented, covering the fundamental principles of FER (including preprocessing, feature extraction, and classification components) from the pre-deep learning era (traditional methods employing handcrafted features such as SVM and HOG) to the advent of deep learning. Furthermore, the paper provides an overview of benchmark datasets (categorized into controlled environments (lab) and uncontrolled environments (in the wild)) utilized for evaluating various FER methods, along with a comparative analysis of different FER models. The discussion also encompasses existing deep neural networks and associated training strategies tailored for FER, focusing on both static images and dynamic image sequences. Finally, the paper addresses the remaining challenges and potential opportunities in FER, while also outlining future directions for the development of robust deep FER systems.",
    "label": 1,
    "type": 5,
    "name": "bla-023"
}