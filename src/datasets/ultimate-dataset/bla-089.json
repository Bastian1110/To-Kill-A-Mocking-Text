{
    "text": "Facial Expression Recognition (FER) finds applications across diverse fields including education, gaming, robotics, healthcare, and more. Techniques like interactive robots equipped with Artificial Intelligence leverage FER to identify human faces, discern the emotions of individuals they interact with, and tailor responses accordingly. One notable application of FER is in selecting music based on the user's mood, where facial expressions are analyzed to infer emotions. However, existing emotion models often struggle to accurately capture the relationship between facial expressions and music. In this study, we employ a Convolutional Neural Network (CNN)-based deep learning approach to address this challenge. Deep learning proves to be more adept at analyzing unstructured data, such as movies and other media, compared to traditional machine learning methods. Our research culminates in the development of a real-time system capable of detecting human faces, evaluating emotions, and offering music recommendations to users. Experimental studies were conducted using the OAHEGA and FER-2013 datasets, where we trained two emotion recognition models using various dataset combinations. The proposed model achieves an accuracy of 73.02% and can predict six emotions: anger, fear, joy, neutral, sadness, and surprise. The versatility of our CNN model makes it applicable in diverse settings where real-time facial recognition is crucial.",
    "label": 1,
    "type": 5,
    "name": "bla-089"
}