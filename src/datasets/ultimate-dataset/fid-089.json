{
    "text": "Facial Expression Recognition (FER) finds application across diverse fields, including education, gaming, robotics, and healthcare. Techniques like interactive robots with Artificial Intelligence leverage FER to detect human emotions during conversations and tailor responses accordingly. One intriguing use case is selecting music based on the user's mood, where facial expression analysis aids in deducing emotions. However, existing emotion models struggle to accurately capture the connection between music and facial emotion, warranting further investigation. This paper employs a Convolution Neural Network (CNN) based deep learning approach to address this challenge. Deep learning proves more adept at analyzing unstructured data, such as movies, than traditional machine learning methods. The research presents a real-time system capable of recognizing human faces, assessing emotions, and recommending music to users. Experimental studies utilize the OAHEGA and FER-2013 datasets, with two emotion recognition models developed and trained using various dataset combinations. The proposed model achieves an accuracy of 73.02%, predicting six emotions: anger, fear, joy, neutral, sadness, and surprise. The system's versatility makes it suitable for deployment in diverse settings where real-time facial recognition is essential.",
    "label": 1,
    "type": 1,
    "name": "fid-089"
}